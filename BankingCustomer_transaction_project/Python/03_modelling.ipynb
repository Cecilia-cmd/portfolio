{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banking Customer & Investment Analysis\n",
    "\n",
    "This notebook explores customer behaviour, transaction patterns, and investment dynamics \n",
    "within a retail banking context.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **0. Import Librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#for part 7:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "#for part 8\n",
    "import os "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Import data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function \n",
    "def read_semicolon_csv(path):\n",
    "    df = pd.read_csv(\n",
    "        path,\n",
    "        sep=\";\",\n",
    "        engine=\"python\",\n",
    "        quoting=csv.QUOTE_NONE\n",
    "    )\n",
    "    #clean quotes \n",
    "    df.columns = df.columns.str.replace('\"', '', regex=False)\n",
    "    return df\n",
    "\n",
    "#apply the function \n",
    "df_customer = read_semicolon_csv(\n",
    "    \"your_path_to_datasets/customer_features.csv\"\n",
    ")\n",
    "\n",
    "df_branch = read_semicolon_csv(\n",
    "    \"your_path_to_datasets/branch_features.csv\"\n",
    ")\n",
    "\n",
    "df_transaction = read_semicolon_csv(\n",
    "    \"your_path_to_datasets/transaction_features.csv\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Verification of importations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification\n",
    "print(df_customer.shape, df_customer.columns.tolist())\n",
    "print(df_branch.shape, df_branch.columns.tolist())\n",
    "print(df_transaction.shape, df_transaction.columns.tolist())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Temporal Variables & Coverage Validation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Quick checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtypes\n",
    "print(df_transaction[[\"txn_year\", \"txn_month\"]].dtypes)\n",
    "\n",
    "#ensure year and month are numeric\n",
    "df_transaction[\"txn_year\"] = pd.to_numeric(df_transaction[\"txn_year\"], errors=\"coerce\")\n",
    "df_transaction[\"txn_month\"] = pd.to_numeric(df_transaction[\"txn_month\"], errors=\"coerce\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Create a synthetic date / period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transaction[\"year_month\"] = (\n",
    "    df_transaction[\"txn_year\"].astype(str) + \"-\" + \n",
    "    df_transaction[\"txn_month\"].astype(str).str.zfill(2)\n",
    ")\n",
    "#convert to pandas Period format (YYYY-MM)\n",
    "df_transaction[\"year_month\"] = pd.PeriodIndex(df_transaction[\"year_month\"], freq=\"M\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Coverage check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time coverage:\")\n",
    "print(\"Earliest period:\", df_transaction[\"year_month\"].min())\n",
    "print(\"Latest period:  \", df_transaction[\"year_month\"].max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. Count how many transactions per period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_counts = df_transaction[\"year_month\"].value_counts().sort_index()\n",
    "print(\"\\nTransactions per period:\")\n",
    "print(period_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Identify missing months (if any) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_range = pd.period_range(\n",
    "    start=df_transaction[\"year_month\"].min(),\n",
    "    end=df_transaction[\"year_month\"].max(),\n",
    "    freq=\"M\"\n",
    ")\n",
    "\n",
    "missing_months = full_range.difference(df_transaction[\"year_month\"].unique())\n",
    "print(\"\\nMissing months:\", missing_months)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Customer EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick overview\n",
    "print(df_customer.head())\n",
    "print(df_customer.describe(include='all'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_customer.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_customer['Age'], bins=20, kde=True)\n",
    "plt.title(\"Customer Age Distribution\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Customer Type breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df_customer, x=\"Customer_Type\")\n",
    "plt.title(\"Customer Type Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Value counts\n",
    "print(\"\\nCustomer Type counts:\")\n",
    "print(df_customer['Customer_Type'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Region distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=df_customer, x=\"customer_region\")\n",
    "plt.title(\"Customer Region Distribution\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRegion counts:\")\n",
    "print(df_customer['customer_region'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Average Balance distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_customer['avg_balance'], bins=30, kde=True)\n",
    "plt.title(\"Average Customer Balance Distribution\")\n",
    "plt.xlabel(\"Average Balance\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Balance vs Investment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(data=df_customer, x='is_investor', y='avg_balance')\n",
    "plt.title(\"Average Balance by Investor Status\")\n",
    "plt.xlabel(\"Is Investor\")\n",
    "plt.ylabel(\"Average Balance\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAverage balance by investor status:\")\n",
    "print(df_customer.groupby('is_investor')['avg_balance'].mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.Transaction EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_transaction.head())\n",
    "print(df_transaction.describe(include='all'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Distribution of Transaction Amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_transaction['Transaction_Amount'], bins=40, kde=True)\n",
    "plt.title(\"Transaction Amount Distribution\")\n",
    "plt.xlabel(\"Transaction Amount\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Distribution of Investment Amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df_transaction['Investment_Amount'], bins=40, kde=True)\n",
    "plt.title(\"Investment Amount Distribution\")\n",
    "plt.xlabel(\"Investment Amount\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(df_transaction[\"Investment_Amount\"].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Investment Type Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df_transaction, x=\"Investment_Type\")\n",
    "plt.title(\"Investment Type Distribution\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "print(df_transaction[\"Investment_Type\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Monthly Transaction Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_by_month = df_transaction.groupby(\"year_month\")[\"Transaction_ID\"].count()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "tx_by_month.plot(kind=\"line\", marker=\"o\")\n",
    "plt.title(\"Monthly Transaction Volume Over Time\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Number of Transactions\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Average Transaction Amount per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tx_month = df_transaction.groupby(\"year_month\")[\"Transaction_Amount\"].mean()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "avg_tx_month.plot(kind=\"line\", marker=\"o\", color=\"orange\")\n",
    "plt.title(\"Average Transaction Amount per Month\")\n",
    "plt.xlabel(\"Year-Month\")\n",
    "plt.ylabel(\"Avg Transaction Amount\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Correlation Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 select relevant numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"Age\",\n",
    "    \"avg_balance\",\n",
    "    \"avg_tx_amount\",\n",
    "    \"avg_investment\",\n",
    "    \"num_transactions\",\n",
    "    \"num_investment_operations\"\n",
    "]\n",
    "\n",
    "df_numeric = df_customer[numeric_cols]\n",
    "df_numeric.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_numeric.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Heatmap of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_matrix, annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Customer Features\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Correlation with investment-related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_related = df_customer[[\"avg_balance\", \"avg_investment\", \"num_investment_operations\"]]\n",
    "print(investment_related.corr())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Probability Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = df_customer.copy()\n",
    "\n",
    "# Create age groups\n",
    "df_prob[\"age_group\"] = pd.cut(\n",
    "    df_prob[\"Age\"],\n",
    "    bins=[18, 30, 45, 60, 80],\n",
    "    labels=[\"18-30\", \"31-45\", \"46-60\", \"61-80\"]\n",
    ")\n",
    "\n",
    "# Define high investors as top 30% investment amount\n",
    "threshold_invest = df_prob[\"avg_investment\"].quantile(0.70)\n",
    "df_prob[\"is_high_investor\"] = (df_prob[\"avg_investment\"] >= threshold_invest).astype(int)\n",
    "\n",
    "# High-frequency investors = top 30% num_investment_operations\n",
    "threshold_freq = df_prob[\"num_investment_operations\"].quantile(0.70)\n",
    "df_prob[\"is_high_freq\"] = (df_prob[\"num_investment_operations\"] >= threshold_freq).astype(int)\n",
    "\n",
    "# High balance = top 30%\n",
    "threshold_balance = df_prob[\"avg_balance\"].quantile(0.70)\n",
    "df_prob[\"is_high_balance\"] = (df_prob[\"avg_balance\"] >= threshold_balance).astype(int)\n",
    "\n",
    "df_prob.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Unconditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_high_invest = df_prob[\"is_high_investor\"].mean()\n",
    "print(\"P(high investment):\", round(p_high_invest, 3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 P(high investment | age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_age = df_prob.groupby(\"age_group\")[\"is_high_investor\"].mean()\n",
    "print(\"\\nP(high investment | age group):\\n\", p_age)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 P(high investment | region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_region = df_prob.groupby(\"customer_region\")[\"is_high_investor\"].mean()\n",
    "print(\"\\nP(high investment | region):\\n\", p_region)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 P(high investment | customer type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_type = df_prob.groupby(\"Customer_Type\")[\"is_high_investor\"].mean()\n",
    "print(\"\\nP(high investment | customer type):\\n\", p_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.5 P(high investment | high balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_balance = df_prob.groupby(\"is_high_balance\")[\"is_high_investor\"].mean()\n",
    "print(\"\\nP(high investment | high balance):\\n\", p_balance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Predictive Analysis**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models:\n",
    "- (1) Logistic Regression → Predict high-value investors\n",
    "- (2) Linear Regression  → Predict average investment amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_prob.copy()\n",
    "\n",
    "# Feature lists\n",
    "cat_features = [\"Customer_Type\", \"customer_region\"]\n",
    "num_features = [\n",
    "    \"Age\", \n",
    "    \"avg_balance\", \n",
    "    \"avg_tx_amount\", \n",
    "    \"num_transactions\",\n",
    "    \"num_investment_operations\"\n",
    "]\n",
    "\n",
    "# Preprocessing object\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\"), cat_features),\n",
    "        (\"num\", \"passthrough\", num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Logistic Regression - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = df_model[cat_features + num_features]\n",
    "y_class = df_model[\"is_high_investor\"]\n",
    "\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_class, y_class, test_size=0.25, random_state=42, stratify=y_class\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Build logisitic regression pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train\n",
    "log_reg_model.fit(X_train_c, y_train_c)\n",
    "\n",
    "# Predict\n",
    "y_pred_c = log_reg_model.predict(X_test_c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Evaluate logistic regresison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Logistic Regression Evaluation ===\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_c, y_pred_c), 3))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_c, y_pred_c))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_c, y_pred_c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 intepret model coefficient (importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature names from the preprocessing step\n",
    "ohe = log_reg_model.named_steps[\"preprocess\"].transformers_[0][1]\n",
    "encoded_cat_names = ohe.get_feature_names_out(cat_features).tolist()\n",
    "all_feature_names = encoded_cat_names + num_features\n",
    "\n",
    "# Extract coefficients\n",
    "coefs = log_reg_model.named_steps[\"classifier\"].coef_[0]\n",
    "importance = sorted(zip(coefs, all_feature_names), reverse=True)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Feature Importance ===\")\n",
    "for coef, name in importance:\n",
    "    print(f\"{name}: {coef:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.5 Linear Regression — Continuous Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg = df_model[cat_features + num_features]\n",
    "y_reg = df_model[\"avg_investment\"]\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "#Build linear regression pipeline\n",
    "lin_reg_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocess),\n",
    "        (\"regressor\", LinearRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train\n",
    "lin_reg_model.fit(X_train_r, y_train_r)\n",
    "\n",
    "# Predict\n",
    "y_pred_r = lin_reg_model.predict(X_test_r)\n",
    "\n",
    "#evaluate\n",
    "print(\"\\n=== Linear Regression Evaluation ===\")\n",
    "print(\"MSE:\", round(mean_squared_error(y_test_r, y_pred_r), 2))\n",
    "print(\"R² Score:\", round(r2_score(y_test_r, y_pred_r), 3))\n",
    "\n",
    "#interprete\n",
    "# Extract regression coefficients\n",
    "reg_coefs = lin_reg_model.named_steps[\"regressor\"].coef_\n",
    "importance_reg = sorted(zip(reg_coefs, all_feature_names), reverse=True)\n",
    "\n",
    "print(\"\\n=== Linear Regression Coefficients ===\")\n",
    "for coef, name in importance_reg:\n",
    "    print(f\"{name}: {coef:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Export dashboard datasets for Tableau**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Export predictions\n",
    "# ============================\n",
    "\n",
    "output_path = \"your_path\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "df_pred = df_model.copy()\n",
    "\n",
    "# Safety check: indices should match\n",
    "assert df_pred.index.equals(df_model.index)\n",
    "\n",
    "# Train/test split flag\n",
    "df_pred[\"split\"] = \"train\"\n",
    "df_pred.loc[X_test_c.index, \"split\"] = \"test\"\n",
    "\n",
    "# Store target for dashboard evaluation\n",
    "df_pred[\"target_is_high_investor\"] = y_class\n",
    "\n",
    "# Logistic regression probability + class\n",
    "df_pred[\"pred_proba_high_investor\"] = log_reg_model.predict_proba(X_class)[:, 1]\n",
    "df_pred[\"pred_class_high_investor\"] = (df_pred[\"pred_proba_high_investor\"] >= THRESHOLD).astype(int)\n",
    "\n",
    "# Linear regression prediction (continuous)\n",
    "df_pred[\"pred_avg_investment\"] = lin_reg_model.predict(X_reg)\n",
    "\n",
    "# Probability deciles (for lift charts / segmentation)\n",
    "df_pred[\"proba_decile\"] = pd.qcut(\n",
    "    df_pred[\"pred_proba_high_investor\"],\n",
    "    q=10,\n",
    "    labels=False,\n",
    "    duplicates=\"drop\"\n",
    ") + 1\n",
    "\n",
    "pred_file = os.path.join(output_path, \"dashboard_predictions.csv\")\n",
    "df_pred.to_csv(pred_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Predictions dataset exported → {pred_file}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Export model coefficients\n",
    "# ============================\n",
    "\n",
    "df_importance_log = pd.DataFrame({\n",
    "    \"feature\": all_feature_names,\n",
    "    \"logistic_coef\": coefs\n",
    "}).sort_values(\"logistic_coef\", ascending=False)\n",
    "\n",
    "df_importance_lin = pd.DataFrame({\n",
    "    \"feature\": all_feature_names,\n",
    "    \"linear_coef\": reg_coefs\n",
    "}).sort_values(\"linear_coef\", ascending=False)\n",
    "\n",
    "importance_log_file = os.path.join(output_path, \"model_importance_logistic.csv\")\n",
    "importance_lin_file = os.path.join(output_path, \"model_importance_linear.csv\")\n",
    "\n",
    "df_importance_log.to_csv(importance_log_file, index=False, encoding=\"utf-8\")\n",
    "df_importance_lin.to_csv(importance_lin_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Logistic importance exported → {importance_log_file}\")\n",
    "print(f\"Linear importance exported → {importance_lin_file}\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Export datasets\n",
    "# ============================\n",
    "\n",
    "customer_file = os.path.join(output_path, \"dashboard_customer.csv\")\n",
    "df_prob.to_csv(customer_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Customer dataset exported → {customer_file}\")\n",
    "\n",
    "transaction_file = os.path.join(output_path, \"dashboard_transaction.csv\")\n",
    "df_transaction_dashboard = df_transaction.copy()\n",
    "df_transaction_dashboard[\"year_month\"] = df_transaction_dashboard[\"year_month\"].astype(str)\n",
    "df_transaction_dashboard.to_csv(transaction_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Transaction dataset exported → {transaction_file}\")\n",
    "\n",
    "branch_file = os.path.join(output_path, \"dashboard_branch.csv\")\n",
    "df_branch.to_csv(branch_file, index=False, encoding=\"utf-8\")\n",
    "print(f\"Branch dataset exported → {branch_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

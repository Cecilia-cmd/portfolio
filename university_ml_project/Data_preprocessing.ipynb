{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiQV0WS0LINvQjieICCL0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cecilia-cmd/2024_MLEES/blob/main/Final_Project/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "_Uz873f8iy_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "#Loading the data\n",
        "folder_path = '/Users/ceciliatorres/Desktop/UNI/ML/Personal_ML_project/Data/'\n",
        "\n",
        "#create different df from different tables\n",
        "otu_abundance = pd.read_csv(folder_path + 'otu_abundance.csv') #OTU = microbial species\n",
        "taxonomy = pd.read_csv(folder_path + 'taxonomy.csv')\n",
        "sample_codes = pd.read_csv(folder_path + 'sample_codes.csv')\n",
        "metadata = pd.read_csv(folder_path + 'metadata.csv')\n",
        "\n",
        "\n",
        "#-------------Cleaning the data --------------------------------------------------\n",
        "\n",
        "#filter sample codes table for SRR identifiers\n",
        "srr_sample_codes = sample_codes[sample_codes['Sample_code'].str.startswith('SRR')]\n",
        "\n",
        "print(srr_sample_codes.columns) #look at the columns name for the dico below\n",
        "\n",
        "#Mapping dico\n",
        "sample_mapping = dict(zip(srr_sample_codes['Kraken2_code '], srr_sample_codes['Sample_code']))\n",
        "        #Kraken2 correspond to the reads name\n",
        "\n",
        "#Filter OTU abundance table to include only SRR data (reads)\n",
        "srr_columns = ['OTU'] + [col for col in otu_abundance.columns if col in sample_mapping]\n",
        "otu_abundance_filtered = otu_abundance[srr_columns]\n",
        "\n",
        "#New columns names with directly the name of metagenomics samples\n",
        "otu_abundance_filtered = otu_abundance_filtered.rename(columns=sample_mapping)\n",
        "\n",
        "##### Now we merge this new otu table with associated information from metadata table #######\n",
        "#first we filter the table 4 with SRR samples form otu_abundance_filtered\n",
        "srr_sample_codes = otu_abundance_filtered.columns  # List of SRR codes after renaming\n",
        "\n",
        "#select only relevant SRR samples and columns in metadata table\n",
        "filtered_metadata = metadata[metadata['Run'].isin(srr_sample_codes)][['Run', 'biome_clean', 'location', 'lat', 'long']]\n",
        "\n",
        "# Remove rows where 'biome_clean' is 'mixed forest' because only 1 data with it and tropcial forest only 3\n",
        "#filtered_metadata = filtered_metadata[filtered_metadata['biome_clean'] != 'mixed forest']\n",
        "filtered_metadata = filtered_metadata[~filtered_metadata['biome_clean'].isin(['mixed forest', 'Tropical forest'])]\n",
        "\n",
        "#rename 'Run' to 'Sample_code' for easier merging with table 2\n",
        "filtered_metadata = filtered_metadata.rename(columns={'Run': 'Sample_code'})\n",
        "#check the filtered metadata to ensure it has the expected SRR samples and columns\n",
        "print(filtered_metadata.head())\n",
        "\n",
        "#Now we are going to merge filtered_metadata with otu_avundance\n",
        "# we transpose table otu_abundance_filtered in order to have the sample ids (=Sample_code) in rows to match the table 4\n",
        "otu_abundance_filtered = otu_abundance_filtered.set_index('OTU').T\n",
        "otu_abundance_filtered.index.name = 'Sample_code'\n",
        "otu_abundance_filtered = otu_abundance_filtered.reset_index()\n",
        "print(otu_abundance_filtered.head())\n",
        "\n",
        "#merge with filtered metadata on the 'Sample_code' column\n",
        "merged_data = otu_abundance_filtered.merge(filtered_metadata, on='Sample_code')\n",
        "print(merged_data.head())\n",
        "\n",
        "\n",
        "##clean if any NAs\n",
        "print(merged_data.isnull().sum())\n",
        "merged_data = merged_data.dropna(subset=['lat', 'long'])\n",
        "\n",
        "print(merged_data['biome_clean'].value_counts())\n",
        "print(merged_data['location'].unique())\n",
        "\n",
        "\n",
        "#-------------Normalize the data -----------------------------------------\n",
        "\n",
        "#we normalize becaue we will use random forest which is better with normalized data\n",
        "otu_columns = [col for col in merged_data.columns if col.startswith('OTU_')]\n",
        "merged_data[otu_columns] = merged_data[otu_columns].div(merged_data[otu_columns].sum(axis=1), axis=0)\n",
        "print(merged_data.head())\n",
        "#save the normalized data (without standardization or splitting)\n",
        "merged_data.to_csv('preprocessed_data.csv', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "wU4ou99uQ3Yd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}